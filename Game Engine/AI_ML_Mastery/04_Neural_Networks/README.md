# Neural Networks and Deep Learning

Mimicking the structure of the human brain to solve complex problems.

## Concepts
- **Perceptrons**: The building blocks of a neural network.
- **Layers**: Input, Hidden, and Output layers.
- **Activation Functions**: Sigmoid, ReLU, Tanh (The "decision-making" part).
- **Backpropagation**: How the network learns from its mistakes.

## Challenge
1. Build a simple neural network from scratch (in Python) to solve the "XOR problem".
2. Use a library like "TensorFlow" or "PyTorch" to train a model that can recognize handwritten digits (MNIST dataset).
3. Research what "Overfitting" is and how to prevent it.
